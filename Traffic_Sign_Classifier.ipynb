{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOMuYfnBeiq-",
        "outputId": "74979ee4-af23-40f6-8d2d-add072bc520b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "     --------------------------------------- 18.1/18.1 MB 25.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (3.5.2)\n",
            "Collecting aiofiles<24.0,>=22.0\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
            "Collecting typer<1.0,>=0.12\n",
            "  Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "     ---------------------------------------- 45.1/45.1 kB ? eta 0:00:00\n",
            "Collecting semantic-version~=2.0\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gradio-client==1.3.0\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "     ---------------------------------------- 318.7/318.7 kB ? eta 0:00:00\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (2.2.3)\n",
            "Collecting pydantic>=2.0\n",
            "  Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "     ------------------------------------- 443.6/443.6 kB 28.9 MB/s eta 0:00:00\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (9.2.0)\n",
            "Collecting urllib3~=2.0\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Collecting uvicorn>=0.14.0\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "     ---------------------------------------- 62.5/62.5 kB ? eta 0:00:00\n",
            "Collecting httpx>=0.24.1\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "     ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
            "Collecting ruff>=0.2.2\n",
            "  Downloading ruff-0.11.6-py3-none-win_amd64.whl (11.6 MB)\n",
            "     --------------------------------------- 11.6/11.6 MB 28.5 MB/s eta 0:00:00\n",
            "Collecting pydub\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (21.3)\n",
            "Collecting orjson~=3.0\n",
            "  Downloading orjson-3.10.16-cp39-cp39-win_amd64.whl (133 kB)\n",
            "     ------------------------------------ 133.6/133.6 kB 986.9 kB/s eta 0:00:00\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (3.5.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio) (4.13.2)\n",
            "Collecting fastapi<1.0\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "     -------------------------------------- 95.2/95.2 kB 679.4 kB/s eta 0:00:00\n",
            "Collecting importlib-resources<7.0,>=1.3\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting tomlkit==0.12.0\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting huggingface-hub>=0.19.3\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "     -------------------------------------- 481.4/481.4 kB 3.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: fsspec in c:\\users\\saura\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2022.7.1)\n",
            "Collecting websockets<13.0,>=10.0\n",
            "  Downloading websockets-12.0-cp39-cp39-win_amd64.whl (124 kB)\n",
            "     ------------------------------------ 125.0/125.0 kB 917.8 kB/s eta 0:00:00\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.3)\n",
            "Collecting starlette<0.47.0,>=0.40.0\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "     ---------------------------------------- 72.0/72.0 kB 4.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: certifi in c:\\users\\saura\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2022.9.14)\n",
            "Collecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 78.7/78.7 kB 4.3 MB/s eta 0:00:00\n",
            "Collecting h11<0.15,>=0.13\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.64.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\saura\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.6.0)\n",
            "Requirement already satisfied: requests in c:\\users\\saura\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.28.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Collecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting typing-inspection>=0.4.0\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Collecting pydantic-core==2.33.1\n",
            "  Downloading pydantic_core-2.33.1-cp39-cp39-win_amd64.whl (2.0 MB)\n",
            "     ---------------------------------------- 2.0/2.0 MB 20.7 MB/s eta 0:00:00\n",
            "Collecting shellingham>=1.3.0\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.0.4)\n",
            "Collecting rich>=10.11.0\n",
            "  Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\saura\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Collecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "     -------------------------------------- 100.9/100.9 kB 6.0 MB/s eta 0:00:00\n",
            "Collecting exceptiongroup>=1.0.2\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting requests\n",
            "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
            "Collecting mdurl~=0.1\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pydub, websockets, urllib3, typing-inspection, tomlkit, shellingham, semantic-version, ruff, python-multipart, pygments, pydantic-core, orjson, mdurl, importlib-resources, h11, fsspec, ffmpy, exceptiongroup, annotated-types, aiofiles, uvicorn, requests, pydantic, markdown-it-py, httpcore, anyio, starlette, rich, huggingface-hub, httpx, typer, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.11\n",
            "    Uninstalling urllib3-1.26.11:\n",
            "      Successfully uninstalled urllib3-1.26.11\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.11.1\n",
            "    Uninstalling tomlkit-0.11.1:\n",
            "      Successfully uninstalled tomlkit-0.11.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.11.2\n",
            "    Uninstalling Pygments-2.11.2:\n",
            "      Successfully uninstalled Pygments-2.11.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2022.7.1\n",
            "    Uninstalling fsspec-2022.7.1:\n",
            "      Successfully uninstalled fsspec-2022.7.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.28.1\n",
            "    Uninstalling requests-2.28.1:\n",
            "      Successfully uninstalled requests-2.28.1\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.5.0\n",
            "    Uninstalling anyio-3.5.0:\n",
            "      Successfully uninstalled anyio-3.5.0\n",
            "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.9.0 exceptiongroup-1.2.2 fastapi-0.115.12 ffmpy-0.5.0 fsspec-2025.3.2 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 huggingface-hub-0.30.2 importlib-resources-6.5.2 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.16 pydantic-2.11.3 pydantic-core-2.33.1 pydub-0.25.1 pygments-2.19.1 python-multipart-0.0.20 requests-2.32.3 rich-14.0.0 ruff-0.11.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.2 tomlkit-0.12.0 typer-0.15.2 typing-inspection-0.4.0 urllib3-2.4.0 uvicorn-0.34.2 websockets-12.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
            "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
            "jupyter-server 1.18.1 requires anyio<4,>=3.1.0, but you have anyio 4.9.0 which is incompatible.\n",
            "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
            "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
            "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
            "botocore 1.27.28 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.4.0 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
            "     ---------------------------------------- 1.6/1.6 MB 9.9 MB/s eta 0:00:00\n",
            "Collecting torch==2.6.0\n",
            "  Downloading torch-2.6.0-cp39-cp39-win_amd64.whl (204.1 MB)\n",
            "     -----------------                      95.0/204.1 MB 16.4 MB/s eta 0:00:07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMRqFcM6hknz",
        "outputId": "cd8479d1-deee-4ed0-ba4a-d08b1acf3c60"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17396\\2813068097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load training and test dataset\n",
        "train_dataset = torchvision.datasets.GTSRB(\n",
        "    root='./data', split='train', download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.GTSRB(\n",
        "    root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# List of class labels\n",
        "# Manual class names\n",
        "classes = [\n",
        "    \"Speed limit (20km/h)\", \"Speed limit (30km/h)\", \"Speed limit (50km/h)\",\n",
        "    \"Speed limit (60km/h)\", \"Speed limit (70km/h)\", \"Speed limit (80km/h)\",\n",
        "    \"End of speed limit (80km/h)\", \"Speed limit (100km/h)\", \"Speed limit (120km/h)\",\n",
        "    \"No passing\", \"No passing for vehicles over 3.5 metric tons\",\n",
        "    \"Right-of-way at the next intersection\", \"Priority road\", \"Yield\", \"Stop\",\n",
        "    \"No vehicles\", \"Vehicles over 3.5 metric tons prohibited\", \"No entry\",\n",
        "    \"General caution\", \"Dangerous curve to the left\", \"Dangerous curve to the right\",\n",
        "    \"Double curve\", \"Bumpy road\", \"Slippery road\", \"Road narrows on the right\",\n",
        "    \"Road work\", \"Traffic signals\", \"Pedestrians\", \"Children crossing\",\n",
        "    \"Bicycles crossing\", \"Beware of ice/snow\", \"Wild animals crossing\",\n",
        "    \"End of all speed and passing limits\", \"Turn right ahead\", \"Turn left ahead\",\n",
        "    \"Ahead only\", \"Go straight or right\", \"Go straight or left\", \"Keep right\",\n",
        "    \"Keep left\", \"Roundabout mandatory\", \"End of no passing\",\n",
        "    \"End of no passing by vehicles over 3.5 metric tons\"\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RahVCzdRh35e"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TrafficSignNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TrafficSignNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 43)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 → 16x16\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 → 8x8\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = TrafficSignNet()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9j6fRwqiBxi",
        "outputId": "e0d05ae7-aacf-4106-875f-949a08617454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.2947314344435858\n",
            "Epoch 2, Loss: 0.19432496428668355\n",
            "Epoch 3, Loss: 0.09118090882982245\n",
            "Epoch 4, Loss: 0.05706507968381315\n",
            "Epoch 5, Loss: 0.03676250735208464\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcHHNnxAirDd"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"gtsrb_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "yqx_agITix37",
        "outputId": "b3bc3bde-dc2f-4315-8d05-9733ad15f2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://17a3814621aa53e022.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://17a3814621aa53e022.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load the trained model\n",
        "model = TrafficSignNet()\n",
        "model.load_state_dict(torch.load(\"gtsrb_model.pth\", map_location=torch.device(\"cpu\")))\n",
        "model.eval()\n",
        "\n",
        "# Predict function with sectional output\n",
        "def predict(img: Image.Image):\n",
        "    image = transform(img).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "        class_name = classes[predicted.item()]\n",
        "        precaution = precautions.get(class_name, \"Drive safely.\")\n",
        "        confidence_pct = confidence.item() * 100\n",
        "\n",
        "        return f\"\"\"\n",
        "<div class='result-section'>\n",
        "  <div class='box detected'>\n",
        "    <h3>🛑 Detected Sign</h3>\n",
        "    <p>{class_name}</p>\n",
        "  </div>\n",
        "  <div class='box confidence'>\n",
        "    <h3>🔒 Confidence</h3>\n",
        "    <p>{confidence_pct:.2f}%</p>\n",
        "  </div>\n",
        "  <div class='box precaution'>\n",
        "    <h3>⚠️ Precaution</h3>\n",
        "    <p>{precaution}</p>\n",
        "  </div>\n",
        "</div>\n",
        "        \"\"\"\n",
        "\n",
        "# Gradio UI with blue theme and sections\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div style=\"text-align:center; padding: 20px;\">\n",
        "        <h1 style=\"font-size: 2.8em; color: #01ffff;\">🚦 Traffic Sign Recognition System</h1>\n",
        "        <p style=\"font-size: 1.2em; color: #1e3799;\">\n",
        "            Upload a traffic sign image to detect the sign and receive real-time precaution tips.\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            image_input = gr.Image(label=\"📷 Upload Traffic Sign\", type=\"pil\")\n",
        "            submit_btn = gr.Button(\"🔍 Predict\", elem_classes=\"custom-button\")\n",
        "        with gr.Column(scale=2):\n",
        "            output_box = gr.HTML(label=\"Prediction Result\")\n",
        "\n",
        "    submit_btn.click(fn=predict, inputs=image_input, outputs=output_box)\n",
        "\n",
        "    # Custom CSS for styling sections\n",
        "    gr.HTML(\"\"\"\n",
        "    <style>\n",
        "        .custom-button {\n",
        "            background: linear-gradient(135deg, #3498db, #2ecc71);\n",
        "            color: white !important;\n",
        "            border: none !important;\n",
        "            border-radius: 10px;\n",
        "            font-size: 1em;\n",
        "            padding: 12px 24px;\n",
        "            transition: 0.3s ease;\n",
        "        }\n",
        "\n",
        "        .custom-button:hover {\n",
        "            background: linear-gradient(135deg, #2980b9, #27ae60);\n",
        "        }\n",
        "\n",
        "        .result-section {\n",
        "            font-family: 'Segoe UI', sans-serif;\n",
        "            color: #01FFF;\n",
        "        }\n",
        "\n",
        "        .box {\n",
        "            background: #01FFF;\n",
        "            border: 2px solid #3498db;\n",
        "            border-radius: 10px;\n",
        "            padding: 15px 20px;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "\n",
        "        .box h3 {\n",
        "            margin: 0 0 5px;\n",
        "            color: #0a3d62;\n",
        "        }\n",
        "\n",
        "        .box p {\n",
        "            font-size: 1.1em;\n",
        "            margin: 0;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\")\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
